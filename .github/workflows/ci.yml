name: ci
on:
  pull_request:
    paths:
      # NOTE: keep these paths in sync with the paths that trigger the
      # fuzzydata Github Actions in .github/workflows/fuzzydata-test.yml
      - .github/workflows/**
      - .github/actions/**
      - '!.github/workflows/push-to-master.yml'
      - asv_bench/**
      - modin/**
      - requirements/**
      - scripts/**
      - environment-dev.yml
      - requirements-dev.txt
      - setup.cfg
      - setup.py
      - versioneer.py
  push:
concurrency:
  # Cancel other jobs in the same branch. We don't care whether CI passes
  # on old commits.
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: ${{ startsWith(github.ref, 'refs/pull/') }}
env:
  MODIN_GITHUB_CI: true

jobs:
  lint-black:
    name: lint (black)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/python-only
      - run: pip install black
      # NOTE: keep the black command here in sync with the pre-commit hook in
      # /contributing/pre-commit
      - run: black --check --diff modin/ asv_bench/benchmarks scripts/doc_checker.py

  lint-mypy:
    name: lint (mypy)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/python-only
      - run: pip install -r requirements-dev.txt
      - run: mypy --config-file mypy.ini

  lint-flake8:
    name: lint (flake8)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/python-only
      # NOTE: If you are changing the set of packages installed here, make sure that
      # the dev requirements match them.
      - run: pip install flake8 flake8-print flake8-no-implicit-concat
      # NOTE: keep the flake8 command here in sync with the pre-commit hook in
      # /contributing/pre-commit
      - run: flake8 modin/ asv_bench/benchmarks scripts/doc_checker.py

  test-api-and-no-engine:
    name: Test API, headers and no-engine mode
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/mamba-env
        with:
          environment-file: requirements/requirements-no-engine.yml
      - run: python -m pytest modin/pandas/test/test_api.py
      - run: python -m pytest modin/test/test_executions_api.py
      - run: python -m pytest modin/test/test_headers.py
      - run: python -m pytest modin/core/execution/dispatching/factories/test/test_dispatcher.py::test_add_option
      - uses: ./.github/actions/upload-coverage

  test-clean-install:
    needs: [lint-flake8, lint-black]
    strategy:
      matrix:
        os:
          - ubuntu
          - windows
    runs-on: ${{ matrix.os }}-latest
    defaults:
      run:
        shell: bash -l {0}
    name: test-clean-install-${{ matrix.os }}
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/python-only
      - run: python -m pip install -e ".[all]"
      - name: Ensure all engines start up
        run: |
          MODIN_ENGINE=dask python -c "import modin.pandas as pd; print(pd.DataFrame([1,2,3]))"
          MODIN_ENGINE=ray python -c "import modin.pandas as pd; print(pd.DataFrame([1,2,3]))"
          MODIN_ENGINE=unidist UNIDIST_BACKEND=mpi mpiexec -n 1 python -c "import modin.pandas as pd; print(pd.DataFrame([1,2,3]))"

  test-internals:
    needs: [lint-flake8, lint-black]
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}
    name: test-internals
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/mamba-env
        with:
          environment-file: environment-dev.yml
      - name: Internals tests
        run: python -m pytest modin/core/execution/dispatching/factories/test/test_dispatcher.py
      - run: python -m pytest modin/config/test
      - run: python -m pytest modin/test/test_envvar_catcher.py
      - run: python -m pytest modin/test/storage_formats/base/test_internals.py
      - run: python -m pytest modin/test/storage_formats/pandas/test_internals.py
      - run: python -m pytest modin/test/test_envvar_npartitions.py
      - run: python -m pytest modin/test/test_utils.py
      - run: python -m pytest asv_bench/test/test_utils.py
      - run: python -m pytest modin/test/interchange/dataframe_protocol/base
      - run: python -m pytest modin/test/test_logging.py
      - uses: ./.github/actions/upload-coverage

  test-defaults:
    needs: [lint-flake8, lint-black]
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}
    strategy:
      matrix:
        execution: [BaseOnPython]
    env:
      MODIN_TEST_DATASET_SIZE: "small"
    name: Test ${{ matrix.execution }} execution, Python 3.9
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/mamba-env
        with:
          environment-file: environment-dev.yml
      - name: Install HDF5
        run: sudo apt update && sudo apt install -y libhdf5-dev
      - name: xgboost tests
        run: |
          # TODO(https://github.com/modin-project/modin/issues/5194): Uncap xgboost
          # when we use collective instead of rabit.
          mamba install "xgboost>=1.7.1,<2.0.0" scikit-learn -c conda-forge
          python -m pytest modin/experimental/xgboost/test/test_default.py --execution=${{ matrix.execution }}
      - run: python -m pytest -n 2 modin/test/storage_formats/base/test_internals.py --execution=${{ matrix.execution }}
      - uses: ./.github/actions/run-core-tests
        with:
          runner: python -m pytest --execution=${{ matrix.execution }}
      - uses: ./.github/actions/upload-coverage

  test-hdk:
    needs: [lint-flake8, lint-black]
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}
    env:
      MODIN_EXPERIMENTAL: "True"
      MODIN_ENGINE: "native"
      MODIN_STORAGE_FORMAT: "hdk"
    name: Test HDK storage format, Python 3.9
    services:
      moto:
        image: motoserver/moto
        ports:
          - 5000:5000
        env:
          AWS_ACCESS_KEY_ID: foobar_key
          AWS_SECRET_ACCESS_KEY: foobar_secret
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/mamba-env
        with:
          environment-file: requirements/env_hdk.yml
          activate-environment: modin_on_hdk
      - name: Install HDF5
        run: sudo apt update && sudo apt install -y libhdf5-dev
      - run: python -m pytest modin/test/storage_formats/hdk/test_internals.py
      - run: python -m pytest modin/experimental/core/execution/native/implementations/hdk_on_native/test/test_init.py
      - run: python -m pytest modin/experimental/core/execution/native/implementations/hdk_on_native/test/test_dataframe.py
      - run: python -m pytest modin/experimental/core/execution/native/implementations/hdk_on_native/test/test_utils.py
      - run: python -m pytest modin/pandas/test/test_io.py --verbose
      - run: python -m pytest modin/test/interchange/dataframe_protocol/test_general.py
      - run: python -m pytest modin/test/interchange/dataframe_protocol/hdk
      - run: python -m pytest modin/experimental/sql/test/test_sql.py
      - run: python -m pytest modin/pandas/test/test_concat.py
      - run: python -m pytest modin/pandas/test/dataframe/test_binary.py
      - run: python -m pytest modin/pandas/test/dataframe/test_reduce.py
      - run: python -m pytest modin/pandas/test/dataframe/test_join_sort.py
      - run: python -m pytest modin/pandas/test/test_general.py
      - run: python -m pytest modin/pandas/test/dataframe/test_indexing.py
      - run: python -m pytest modin/pandas/test/test_series.py
      - run: python -m pytest modin/pandas/test/dataframe/test_map_metadata.py
      - run: python -m pytest modin/pandas/test/dataframe/test_window.py
      - run: python -m pytest modin/pandas/test/dataframe/test_default.py
      - run: python examples/docker/modin-hdk/census-hdk.py examples/data/census_1k.csv -no-ml
      - run: python examples/docker/modin-hdk/nyc-taxi-hdk.py examples/data/nyc-taxi_1k.csv
      - run: |
          python examples/docker/modin-hdk/plasticc-hdk.py \
          examples/data/plasticc_training_set_1k.csv \
          examples/data/plasticc_test_set_1k.csv \
          examples/data/plasticc_training_set_metadata_1k.csv \
          examples/data/plasticc_test_set_metadata_1k.csv \
          -no-ml
      - uses: ./.github/actions/upload-coverage

  test-asv-benchmarks:
    if: github.event_name == 'pull_request'
    needs: [lint-flake8, lint-black]
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}
    env:
      MODIN_ENGINE: ray
      MODIN_MEMORY: 1000000000
      MODIN_TEST_DATASET_SIZE: small
    name: test-asv-benchmarks
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 1
      - uses: conda-incubator/setup-miniconda@v2
        with:
          auto-activate-base: true
          activate-environment: ""
          miniforge-variant: Mambaforge
          miniforge-version: latest
          use-mamba: true
      - name: ASV installation
        run: pip install asv==0.5.1
      - name: Running benchmarks
        run: |
          git remote add upstream https://github.com/modin-project/modin.git
          git fetch upstream
          if git diff upstream/master --name-only | grep -q "^asv_bench/"; then
              # ASV correctly creates environments for testing only from the branch
              # with `master` name
              git checkout -b master
              cd asv_bench
              asv check -v

              asv machine --yes

              # check Modin on Ray
              asv run --quick --strict --show-stderr --launch-method=spawn \
                -b ^benchmarks -b ^io -b ^scalability | tee benchmarks.log

              # check pure pandas
              MODIN_ASV_USE_IMPL=pandas asv run --quick --strict --show-stderr --launch-method=spawn \
                -b ^benchmarks -b ^io | tee benchmarks.log

              # HDK: ERR_OUT_OF_CPU_MEM: Not enough host memory to execute the query (MODIN#4270)
              # just disable test for testing - it works well in a machine with more memory
              sed -i 's/def time_groupby_agg_nunique(self, \*args, \*\*kwargs):/# def time_groupby_agg_nunique(self, *args, **kwargs):/g' benchmarks/hdk/benchmarks.py
              sed -i 's/execute(self.df.groupby(by=self.groupby_columns).agg("nunique"))/# execute(self.df.groupby(by=self.groupby_columns).agg("nunique"))/g' benchmarks/hdk/benchmarks.py

              # Otherwise, ASV considers that the environment has already been created, although ASV command is run for another config,
              # which requires the creation of a completely new environment. This step will be required after removing the manual environment setup step.
              rm -f -R .asv/env/

              # TODO: Remove manual environment creation after fix https://github.com/airspeed-velocity/asv/issues/1310
              mamba env create -f ../requirements/env_hdk.yml
              conda activate modin_on_hdk
              pip install asv==0.5.1
              pip install ..

              # check Modin on HDK
              MODIN_ENGINE=native MODIN_STORAGE_FORMAT=hdk MODIN_EXPERIMENTAL=true asv run --quick --strict --show-stderr \
                --launch-method=forkserver --python=same --config asv.conf.hdk.json \
                -b ^hdk | tee benchmarks.log
          else
              echo "Benchmarks did not run, no changes detected"
          fi
        if: always()

      - name: Publish benchmarks artifact
        uses: actions/upload-artifact@master
        with:
          name: Benchmarks log
          path: asv_bench/benchmarks.log
        if: failure()

  execution-filter:
    # see if execution backend-specific changes were made
    runs-on: ubuntu-latest
    outputs:
      ray: ${{ steps.filter.outputs.ray }}
      dask: ${{ steps.filter.outputs.dask }}
      unidist: ${{ steps.filter.outputs.unidist }}
      engines: ${{ steps.engines.outputs.engines }}
      experimental: ${{ steps.experimental.outputs.experimental }}
    steps:
    - uses: actions/checkout@v3
    - uses: dorny/paths-filter@v2
      id: filter
      with:
        filters: |
          shared: &shared
            - 'modin/core/execution/dispatching/**'
          ray:
            - *shared
            - 'modin/core/execution/ray/**'
          dask:
            - *shared
            - 'modin/core/execution/dask/**'
          unidist:
            - *shared
            - 'modin/core/execution/unidist/**'
          experimental:
            - 'modin/experimental/**'
    - uses: actions/setup-python@v4
    - id: engines
      run: |
        python -c "import sys, json; print('engines=' + json.dumps(['python'] + (sys.argv[1] == 'true' and ['ray'] or []) + (sys.argv[2] == 'true' and ['dask'] or []) ))" \
              "${{ steps.filter.outputs.ray }}" "${{ steps.filter.outputs.dask }}" >> $GITHUB_OUTPUT

  upload-coverage:
    needs: [test-internals, test-api-and-no-engine, test-defaults, test-hdk]
    if: always()  # we need to run it regardless of some job being skipped, like in PR
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/python-only
      - name: Download coverage data
        uses: actions/download-artifact@v3.0.2
        with:
          name: coverage-data
      - run: pip install coverage
      - name: Combine coverage
        run: python -m coverage combine
      - name: Generate coverage report in xml format
        run: python -m coverage xml
      - uses: codecov/codecov-action@v3
        with:
          fail_ci_if_error: ${{ github.event_name == 'push' }}  # do not care about uploads in PR
